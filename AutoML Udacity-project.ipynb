{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-146358\n",
      "Azure region: southcentralus\n",
      "Subscription id: f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n",
      "Resource group: aml-quickstarts-146358\n"
     ]
    }
   ],
   "source": [
    "# Create a new workspace and define an experiment.\n",
    "\n",
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "#ws = Workspace.get(name=\"udacity-project\")\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "# Choose a name for the experiment\n",
    "experiment_name = 'udacity-project-automl'\n",
    "experiment = Experiment(workspace=ws, name = experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create a compute cluster to provision VM Resources.\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Choose a name for the cluster\n",
    "cpu_cluster_name = 'cpu-cluster-01'\n",
    "\n",
    "#Verify that the culster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = ws, name = cpu_cluster_name)\n",
    "    print('Found existing cluster, use it')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_D2_V2', max_nodes = 4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1616826843997
    }
   },
   "outputs": [],
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = 'f9d5a085-54dc-4215-9ba6-dad5d86e60a0'\n",
    "resource_group = 'aml-quickstarts-146358'\n",
    "workspace_name = 'quick-starts-ws-146358'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='Adult')\n",
    "\n",
    "ds = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1616827026535
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "\n",
    "#automl settings have the optios to assign the dataframe and identify a target variable within it.\n",
    "datafinal = pd.concat([x,y], axis = 1)\n",
    "\n",
    "ds = datafinal\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes = 30,\n",
    "    compute_target = compute_target,\n",
    "    primary_metric = 'accuracy',\n",
    "    n_cross_validations = 3, #typically 5, used to make time go quicker.\n",
    "    task = 'classification',\n",
    "    training_data = ds,\n",
    "    label_column_name = 'wage',\n",
    "    enable_onnx_compatible_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes = 30,\n",
    "    primary_metric = 'accuracy',\n",
    "    n_cross_validations = 3, #typically 5, used to make time go quicker.\n",
    "    task = 'classification',\n",
    "    training_data = ds,\n",
    "    label_column_name = 'wage',\n",
    "    enable_onnx_compatible_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No run_configuration provided, running on local with default configuration\n",
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-project-automl</td><td>AutoML_ff5bbe9c-f318-4a96-b4fd-a445b5b58871</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_ff5bbe9c-f318-4a96-b4fd-a445b5b58871?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-146358/workspaces/quick-starts-ws-146358&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:26       0.8691    0.8691\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:27       0.8631    0.8691\n",
      "         2   MaxAbsScaler RandomForest                      0:00:25       0.8352    0.8691\n",
      "         3   MaxAbsScaler RandomForest                      0:00:26       0.7935    0.8691\n",
      "         4   MaxAbsScaler RandomForest                      0:00:26       0.7335    0.8691\n",
      "         5   MaxAbsScaler RandomForest                      0:00:24       0.7222    0.8691\n",
      "         6   SparseNormalizer XGBoostClassifier             0:00:28       0.8631    0.8691\n",
      "         7   MaxAbsScaler GradientBoosting                  0:00:29       0.8243    0.8691\n",
      "         8   StandardScalerWrapper RandomForest             0:00:26       0.8443    0.8691\n",
      "         9   MaxAbsScaler LogisticRegression                0:00:27       0.8492    0.8691\n",
      "        10   MaxAbsScaler LightGBM                          0:00:24       0.8143    0.8691\n",
      "        11   SparseNormalizer XGBoostClassifier             0:00:29       0.8629    0.8691\n",
      "        12   MaxAbsScaler ExtremeRandomTrees                0:00:48       0.8128    0.8691\n",
      "        13   StandardScalerWrapper LightGBM                 0:00:27       0.7636    0.8691\n",
      "        14   SparseNormalizer XGBoostClassifier             0:00:40       0.8675    0.8691\n",
      "        15   SparseNormalizer LightGBM                      0:00:26       0.8155    0.8691\n",
      "        16   MaxAbsScaler LogisticRegression                0:00:29       0.8478    0.8691\n",
      "        17   StandardScalerWrapper LightGBM                 0:00:25       0.7716    0.8691\n",
      "        18   StandardScalerWrapper ExtremeRandomTrees       0:00:33       0.7987    0.8691\n",
      "        19   SparseNormalizer LightGBM                      0:00:28       0.8491    0.8691\n",
      "        20   SparseNormalizer XGBoostClassifier             0:00:26       0.8317    0.8691\n",
      "        21   StandardScalerWrapper LightGBM                 0:00:28       0.7942    0.8691\n",
      "        22   SparseNormalizer XGBoostClassifier             0:02:51       0.8487    0.8691\n",
      "        23   SparseNormalizer XGBoostClassifier             0:00:30       0.8659    0.8691\n",
      "        24   SparseNormalizer XGBoostClassifier             0:00:30       0.8625    0.8691\n",
      "        25   MaxAbsScaler LightGBM                          0:00:25       0.7592    0.8691\n",
      "        26   SparseNormalizer LightGBM                      0:00:25       0.8463    0.8691\n",
      "        27   StandardScalerWrapper XGBoostClassifier        0:00:38       0.8570    0.8691\n",
      "        28   MaxAbsScaler LogisticRegression                0:00:31       0.8089    0.8691\n",
      "        29   SparseNormalizer XGBoostClassifier             0:00:35       0.8661    0.8691\n",
      "        30   SparseNormalizer LightGBM                      0:00:28       0.7957    0.8691\n",
      "        31   SparseNormalizer XGBoostClassifier             0:00:30       0.8629    0.8691\n",
      "        32   "
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "experiment = Experiment(ws, 'udacity-project-automl')\n",
    "automl_run = experiment.submit(config = automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azureml-train-automl-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.train.automl\n",
    "\n",
    "import azureml.automl.core\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "\n",
    "best_automl_run, best_automl_onnx_model = automl_run.get_output(return_onnx_model = True)\n",
    "OnnxConverter.save_onnx_model(best_automl_onnx_model, file_path = 'outputs/best_automl_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
