{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Machine Learning Engineer\n",
        "## Project 3 - Capstone Hyperdrive\n",
        "\n",
        "## Create a workspace\n",
        "In this step we are making an Azure Workspace and setting up an experiment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new workspace and define an experiment.\n",
        "\n",
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "#ws = Workspace.get(name=\"udacity-project\")\n",
        "ws = Workspace.from_config()\n",
        "ws.get_details()\n",
        "\n",
        "# Choose a name for the experiment\n",
        "experiment_name = 'udacity-project-hyperdrive'\n",
        "experiment = Experiment(workspace=ws, name = experiment_name)\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = experiment.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-146693\n",
            "Azure region: southcentralus\n",
            "Subscription id: 610d6e37-4747-4a20-80eb-3aad70a55f43\n",
            "Resource group: aml-quickstarts-146693\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1623057847055
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an environment\n",
        "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - xgboost"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Environment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "myenv = Environment.get(workspace=ws, name=\"AzureML-Minimal\")\n",
        "sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1623057865852
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Compute\n",
        "Create a new compute or use an existing one if its present"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a compute cluster to provision VM Resources.\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "# Choose a name for the cluster\n",
        "cpu_cluster_name = 'cpu-cluster-01'\n",
        "\n",
        "#Verify that the culster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace = ws, name = cpu_cluster_name)\n",
        "    print('Found existing cluster, use it')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_D2_V2', max_nodes = 4)\n",
        "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1623057875969
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "#experiment = Experiment(ws, experiment_name)\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config, show_output = True)\n",
        "\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Hyperparameter Tuning with Hyperdrive.\n",
        "\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform,choice\n",
        "import os\n",
        "import shutil\n",
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "#Define the parameter search space/method\n",
        "# Specify parameter sampler, in this case we are looking to get defined ranges and pass back to the SKILEARN\n",
        "# training model.\n",
        "# we can define RandomParameterSampling, Grid Sampling or Bayesian sampling\n",
        "# ie. ps = GridParameterSampling.... this would require importing from azureml.train.hyperdrive import GridParameterSampling\n",
        "\n",
        "ps = RandomParameterSampling({\n",
        "    '--max_depth' : choice(2,5), #limited for simplicity\n",
        "    '--learning_rate' : choice (0.1,1) #limited for simplicity\n",
        "})\n",
        "\n",
        "# Specify an early termination Policy\n",
        "# Other options are median policy, have stuck with bandit for simplification\n",
        "# Bandit policy stops if its less than 10% of best model, starting and interval 5\n",
        "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
        "\n",
        "#creates a training director.\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "    \n",
        "script_folder = './training'\n",
        "\n",
        "os.makedirs(script_folder, exist_ok = True)\n",
        "\n",
        "shutil.copy('./trainurl.py',script_folder)\n",
        "\n",
        "# Create a SKLearn estimator for use with train.py\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script='trainurl.py',\n",
        "                      environment=sklearn_env\n",
        ")\n",
        "\n",
        "src.run_config.target = compute_target\n",
        "\n",
        "hyperdrive_config = HyperDriveConfig(estimator = src,\n",
        "                                     hyperparameter_sampling = ps,\n",
        "                                     policy = early_termination_policy,\n",
        "                                     primary_metric_name = 'Accuracy', #Accuracy for classification\n",
        "                                     primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs = 50,\n",
        "                                     max_concurrent_runs = 4)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1623058246309
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azureml-core"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: azureml-core\n",
            "Version: 1.28.0\n",
            "Summary: Azure Machine Learning core packages, modules, and classes\n",
            "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\n",
            "Author: Microsoft Corp\n",
            "Author-email: None\n",
            "License: https://aka.ms/azureml-sdk-license\n",
            "Location: /anaconda/envs/azureml_py36/lib/python3.6/site-packages\n",
            "Requires: pytz, ndg-httpsclient, pyopenssl, pathspec, azure-mgmt-authorization, contextlib2, jsonpickle, backports.tempfile, msrestazure, azure-mgmt-containerregistry, adal, azure-mgmt-keyvault, azure-common, azure-mgmt-storage, jmespath, cryptography, python-dateutil, SecretStorage, requests, docker, azure-mgmt-resource, ruamel.yaml, azure-graphrbac, msrest, urllib3, PyJWT\n",
            "Required-by: azureml-widgets, azureml-train-core, azureml-train-automl-runtime, azureml-train-automl-client, azureml-tensorboard, azureml-telemetry, azureml-sdk, azureml-pipeline-core, azureml-opendatasets, azureml-mlflow, azureml-interpret, azureml-defaults, azureml-datadrift, azureml-contrib-services, azureml-contrib-server, azureml-contrib-reinforcementlearning, azureml-contrib-pipeline-steps, azureml-contrib-notebook, azureml-contrib-gbdt, azureml-contrib-fairness, azureml-contrib-dataset, azureml-cli-common, azureml-automl-dnn-nlp, azureml-accel-models\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623058325251
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "#experiment = Experiment(ws, experiment_name)\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config, show_output = True)\n",
        "\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ScriptRunConfig' object has no attribute '_compute_target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a897cbdbade2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#experiment = Experiment(ws, experiment_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhyperdrive_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/hyperdrive/_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(hyperdrive_config, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ScriptRunConfig' object has no attribute '_compute_target'"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "best_hyperdrive_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "#best_hyperdrive_run_metrics = best_hyperdrive_run.get_metrics()\n",
        "\n",
        "print(\"Best Run Metrics :\", best_hyperdrive_run.get_metrics())\n",
        "\n",
        "best_hyperdrive_run.download_file(\n",
        "    best_hyperdrive_run.get_file_names()[-1],\n",
        "    output_file_path=\"./outputs/\"\n",
        ")\n",
        "best_hyperdrive_model = best_hyperdrive_run.register_model(\n",
        "    model_name=\"best_hyperdrive_model\",\n",
        "    model_path=\"./outputs/best_hyperdrive_model.joblib\",\n",
        "    tags=best_hyperdrive_run.get_metrics()\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Run Metrics : {'Accuracy': 0.8686661889650936, 'Max depth:': 2.0, 'Learning rate:': 1}\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}